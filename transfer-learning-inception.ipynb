{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from keras.models import load_model\n", "import tensorflow as tf\n", "from keras.layers import Input, Lambda, Dense, Flatten\n", "from keras.models import Model\n", "from keras.applications.inception_v3 import InceptionV3\n", "from keras.applications.inception_v3 import preprocess_input\n", "from keras.preprocessing import image\n", "from keras.preprocessing.image import ImageDataGenerator\n", "from keras.models import Sequential\n", "import numpy as np\n", "from glob import glob\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["re-size all the images to this"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["IMAGE_SIZE = [400, 400]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_path = 'ebhi-split-2categorias/train'\n", "valid_path = 'ebhi-split-2categorias/val'\n", "test_path = 'ebhi-split-2categorias/test'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["add preprocessing layer to the front of inception"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["inception = InceptionV3(input_shape=IMAGE_SIZE +\n", "                        [3], weights='imagenet', include_top=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["don't train existing weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for layer in inception.layers:\n", "    layer.trainable = False\n\n", "    # useful for getting number of classes\n", "folders = glob(train_path + '/*')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["our layers - you can add more if you want"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x = Flatten()(inception.output)\n", "# x = Dense(1000, activation='relu')(x)\n", "#prediction = Dense(len(folders), activation='softmax')(x)\n", "prediction = Dense(1, activation='sigmoid')(x)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create a model object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = Model(inputs=inception.input, outputs=prediction)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["view the structure of the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["tell the model what cost and optimization method to use"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.compile(\n", "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n", "    optimizer='adam',\n", "    metrics=['accuracy']\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_datagen = ImageDataGenerator(rescale=1./255,\n", "                                   shear_range=0.2,\n", "                                   zoom_range=0.2,\n", "                                   horizontal_flip=True)\n", "valid_datagen = ImageDataGenerator(rescale=1./255)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test_datagen = ImageDataGenerator(rescale=1./255)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["training_set = train_datagen.flow_from_directory(train_path,\n", "                                                 target_size=(400, 400),\n", "                                                 batch_size=32,\n", "                                                 class_mode='binary')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["valid_set = valid_datagen.flow_from_directory(valid_path,\n", "                                              target_size=(400, 400),\n", "                                              batch_size=32,\n", "                                              class_mode='binary')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test_set = test_datagen.flow_from_directory(test_path,\n", "                                            target_size=(400, 400),\n", "                                            batch_size=32,\n", "                                            class_mode='binary')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["fit the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["r = model.fit(\n", "    training_set,\n", "    validation_data=valid_set,\n", "    epochs=5,\n", "    steps_per_epoch=len(training_set),\n", "    validation_steps=len(valid_set)\n", ")\n", "# loss\n", "plt.plot(r.history['loss'], label='train loss')\n", "plt.plot(r.history['val_loss'], label='val loss')\n", "plt.legend()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.savefig('LossVal_loss_inception')\n", "plt.show()\n", "# accuracies\n", "plt.plot(r.history['accuracy'], label='train acc')\n", "plt.plot(r.history['val_accuracy'], label='val acc')\n", "plt.legend()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.savefig('AccVal_acc_inception')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.save('hist_model_inception.h5')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}